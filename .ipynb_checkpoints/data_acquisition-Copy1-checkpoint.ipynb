{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pathlib import Path\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cursor_data():\n",
    "    \"\"\"Create an empty csv file for keeping track of cursors obtained from Steam's getreview \n",
    "    API where cursors are URL Encoded strings used to query the next batch of data.\n",
    "    \n",
    "    https://partner.steamgames.com/doc/store/getreviews contains more information regarding\n",
    "    the API\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    file = Path('data/cursor_data.csv')\n",
    "    \n",
    "    if (file.exists()):\n",
    "        print(\"cursor data already exists\")\n",
    "    else:\n",
    "        initial_cursor_data = {\"batch\": 0, \"cursor\": ['*']}\n",
    "\n",
    "        cursor_data = pd.DataFrame(data=initial_cursor_data)\n",
    "        cursor_data.to_csv('data/cursor_data.csv', index=False)\n",
    "        \n",
    "def initialize_raw_data():\n",
    "    \"\"\"Create an empty csv file for the raw review data - refer to \n",
    "    column_names below for the data contained\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    file = Path('data/raw_data.csv')\n",
    "    \n",
    "    if (file.exists()):\n",
    "        print(\"raw data already exists\")\n",
    "    else:\n",
    "        column_names = ['recommendationid', 'author', 'language', 'review', \n",
    "                        'timestamp_created', 'timestamp_updated', 'voted_up',\n",
    "                        'votes_funny', 'weighted_vote_score', 'comment_count',\n",
    "                        'steam_purchase', 'received_for_free', \n",
    "                        'written_during_early_access']\n",
    "        \n",
    "        raw_data = pd.DataFrame(columns=column_names)\n",
    "        raw_data.to_csv('data/raw_data.csv', index=False)\n",
    "        print(\"raw data initialized\")\n",
    "        \n",
    "def initialize_review_data():\n",
    "    \"\"\"Create an empty csv file for cleaned data that includes a user's steam id,\n",
    "    their review, the (Unix) timestamp for when it was created and whether or not \n",
    "    the user recommended the game.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    file = Path('data/review_data.csv')\n",
    "    \n",
    "    if (file.exists()):\n",
    "        print(\"review data already exists\")\n",
    "    else:\n",
    "        column_names = ['steam_id', 'review', 'timestamp_created', 'voted_up']\n",
    "        \n",
    "        data = pd.DataFrame(columns=column_names)\n",
    "        data.to_csv('data/review_data.csv', index=False)\n",
    "        print(\"review data initialized\")\n",
    "        \n",
    "def initialize_backup_directory():\n",
    "    \"\"\"Create an empty folder for backup data\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    directory_name = 'data/backup_data'\n",
    "    if os.path.exists(directory_name):\n",
    "        print(directory_name, \"directory already exists\")\n",
    "    else:\n",
    "        os.mkdir(directory_name)\n",
    "        print(directory_name, \"directory initialized\")\n",
    "\n",
    "def get_next_cursor():\n",
    "    \"\"\"Get the cursor for the next query from cursor_data.csv\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        next_cursor (string): URL Encoded string used to obtain the next batch of data\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor_data = pd.read_csv('data/cursor_data.csv')\n",
    "    next_cursor = cursor_data['cursor'].iloc[-1]\n",
    "    return next_cursor\n",
    "\n",
    "def get_next_url(next_cursor):\n",
    "    \"\"\"Get the url containing the next batch of data\n",
    "    \n",
    "    Args:\n",
    "        next_cursor (string): URL Encoded string used to obtain the next batch of data\n",
    "        \n",
    "    Returns:\n",
    "        next_url (string): the url containing the next batch of data\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = 'https://store.steampowered.com/appreviews/322330?json=1&day_range=9223372036854775807\\\n",
    "                &language=\"English\"&num_per_page=100&cursor='\n",
    "    next_url = base_url + next_cursor\n",
    "    return next_url\n",
    "    \n",
    "def get_data(num_batches): \n",
    "    \"\"\"Get the raw review data and cursors\n",
    "    \n",
    "    Args:\n",
    "        num_batches (int): the number of data batches to be queried where each batch contains\n",
    "                           100 reviews\n",
    "        \n",
    "    Returns:\n",
    "        review_data (dataframe): the raw review data \n",
    "        cursor_data (array): cursors used to query the data \n",
    "    \"\"\"\n",
    "    \n",
    "    cursor_data = []\n",
    "    column_names = ['recommendationid', 'author', 'language', 'review', \n",
    "                    'timestamp_created', 'timestamp_updated', 'voted_up',\n",
    "                    'votes_funny', 'weighted_vote_score', 'comment_count',\n",
    "                    'steam_purchase', 'received_for_free', \n",
    "                    'written_during_early_access']\n",
    "    review_data = pd.DataFrame(columns=column_names)\n",
    "    next_cursor = get_next_cursor()\n",
    "    \n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        next_url = get_next_url(next_cursor)\n",
    "\n",
    "        r = requests.get(next_url)\n",
    "        json_data = json.loads(r.text) \n",
    "\n",
    "        new_review_data = pd.DataFrame(data = json_data['reviews'])\n",
    "        review_data = review_data.append(new_review_data, ignore_index=True, sort=True)\n",
    "\n",
    "        next_cursor = urllib.parse.quote(json_data['cursor'])\n",
    "        cursor_data.append(next_cursor)\n",
    "    \n",
    "    return review_data, cursor_data\n",
    "\n",
    "def update_cursor_data(new_cursors):\n",
    "    \"\"\"Create a backup of the cursor data and update it \n",
    "    \n",
    "    Args:\n",
    "        new_cursors (array): contains cursors corresponding to the queried data along \n",
    "                             with a cursor that can be used to query the next batch of data\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor_data = pd.read_csv('data/cursor_data.csv')\n",
    "    cursor_data.to_csv('data/backup_data/cursor_data_backup.csv', index=False)\n",
    "    \n",
    "    initial_length = cursor_data.shape[0]\n",
    "    final_length = initial_length + len(new_cursors)\n",
    "    \n",
    "    new_cursor_data = pd.DataFrame({'batch': range(initial_length, final_length),\n",
    "                                    'cursor': new_cursors})\n",
    "    \n",
    "    updated_cursor_data = cursor_data.append(new_cursor_data, ignore_index=True)\n",
    "    updated_cursor_data.to_csv('data/cursor_data.csv', index=False)\n",
    "    \n",
    "def update_raw_data(new_data):\n",
    "    \"\"\"Create a backup of the raw data and update it \n",
    "    \n",
    "    Args:\n",
    "        new_data (dataframe): contains new raw data to be added\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_data = pd.read_csv('data/raw_data.csv')\n",
    "    raw_data.to_csv('data/backup_data/raw_data_backup.csv', index=False)\n",
    "    \n",
    "    updated_raw_data = raw_data.append(new_data, ignore_index=True, sort=True)\n",
    "    updated_raw_data.to_csv('data/raw_data.csv', index = False)\n",
    "\n",
    "def clean_author_data(data):\n",
    "    data['author'] = data['author'].apply(lambda x: x.get('steamid'))\n",
    "    data.rename(columns = {'author': 'steam_id'}, inplace=True)\n",
    "    return data\n",
    "\n",
    "def clean_reviews(data):\n",
    "    data['review'] = data['review'].astype(str)\n",
    "    data['review'] = data['review'].apply(lambda x: x.replace('\\n', ' '))\n",
    "    return data\n",
    "    \n",
    "def clean_data(raw_data):\n",
    "    \"\"\"Cleans user reviews by dropping unnecessary columns, re-mapping author\n",
    "    to steam_id and removing newlines from reviews\n",
    "    \n",
    "    Args:\n",
    "        raw_data (dataframe): contains the raw data to be cleansed\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    trimmed_data = raw_data[['author', 'review', 'timestamp_created', 'voted_up']].copy()\n",
    "    \n",
    "    intermediate_data = clean_author_data(trimmed_data)\n",
    "    cleansed_data = clean_reviews(intermediate_data)\n",
    "    return cleansed_data\n",
    "\n",
    "def update_review_data(new_data):\n",
    "    \"\"\"Create a backup of the cleansed data and update it \n",
    "    \n",
    "    Args:\n",
    "        new_data (dataframe): contains the cleansed data to be added\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_csv('data/review_data.csv')\n",
    "    data.to_csv('data/backup_data/review_data_backup.csv', index=False)\n",
    "    \n",
    "    updated_data = data.append(new_data, ignore_index=True)\n",
    "    updated_data.to_csv('data/review_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cursor data already exists\n",
      "raw data already exists\n",
      "review data already exists\n",
      "data/backup_data directory already exists\n"
     ]
    }
   ],
   "source": [
    "# create csv files for data if they do not exist\n",
    "initialize_cursor_data()\n",
    "initialize_raw_data()\n",
    "initialize_review_data()\n",
    "initialize_backup_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:37<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# fetch and clean new data \n",
    "# the input of get_data() corresponds to the number of data batches fetched where each batch contains 100 reviews\n",
    "new_data = get_data(100)\n",
    "new_raw_data = new_data[0]\n",
    "new_cursors = new_data[1]\n",
    "\n",
    "update_cursor_data(new_cursors)\n",
    "update_raw_data(new_raw_data)\n",
    "\n",
    "new_review_data = clean_data(new_raw_data)\n",
    "update_review_data(new_review_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
